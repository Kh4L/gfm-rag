hydra:
  run:
    dir: outputs/qa_inference/${dataset.data_name}/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - _self_
  - doc_ranker: topk_ranker

seed: 1024

dataset:
  root: ./data
  data_name: hotpotqa_example

llm:
  _target_: deep_graphrag.llms.ChatGPT
  model_name_or_path: gpt-3.5-turbo
  retry: 5

graph_retriever:
  model_path: save_models/qa_ultra_epoch_20/

test:
  retrieval_batch_size: 8
  top_k: 5
  save_top_k_entity: 10
  save_retrieval: False
  metric: [em, f1, precision, recall]
  evaluator:
    _target_: deep_graphrag.evaluation.hotpot_qa_evaluator.HotpotQAEvaluator
  n_threads: 5
  prompt_mode: "one-shot"
